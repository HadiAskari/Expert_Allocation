{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haskari/miniconda3/envs/alphalora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import re\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qa_text_scienceq_train_all.json', 'r') as f:\n",
    "    train=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': None,\n",
       " 'question': 'Which tense does the sentence use?\\nMona will print her name with care.',\n",
       " 'choices': ['present tense', 'future tense', 'past tense'],\n",
       " 'answer': 'B',\n",
       " 'hint': '',\n",
       " 'task': 'closed choice',\n",
       " 'grade': 'grade2',\n",
       " 'subject': 'language science',\n",
       " 'topic': 'verbs',\n",
       " 'category': 'Verb tense',\n",
       " 'skill': 'Is the sentence in the past, present, or future tense?',\n",
       " 'lecture': 'Present tense verbs tell you about something that is happening now.\\nMost present-tense verbs are regular. They have no ending, or they end in -s or -es.\\nTwo verbs are irregular in the present tense, to be and to have. You must remember their forms.\\nPast tense verbs tell you about something that has already happened.\\nMost past-tense verbs are regular. They end in -ed.\\nSome verbs are irregular in the past tense. You must remember their past-tense forms.\\nFuture tense verbs tell you about something that is going to happen.\\nAll future-tense verbs use the word will.\\nPresent | Past | Future\\nwalk, walks | walked | will walk\\ngo, goes | went | will go',\n",
       " 'solution': 'The sentence is in future tense. You can tell because it uses will before the main verb, print. The verb tells you about something that is going to happen.',\n",
       " 'input': '',\n",
       " 'instruction': 'Context: N/A\\nQuestion: Which tense does the sentence use?\\nMona will print her name with care.\\nOptions: (A) present tense (B) future tense (C) past tense\\n',\n",
       " 'output': 'Answer: The answer is B.'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qa_text_scienceq_validation_all.json', 'r') as f:\n",
    "    val=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': None,\n",
       " 'question': \"What does the verbal irony in this text suggest?\\nAccording to Mr. Herrera's kids, his snoring is as quiet as a jackhammer.\",\n",
       " 'choices': ['The snoring is loud.', 'The snoring occurs in bursts.'],\n",
       " 'answer': 'A',\n",
       " 'hint': '',\n",
       " 'task': 'closed choice',\n",
       " 'grade': 'grade8',\n",
       " 'subject': 'language science',\n",
       " 'topic': 'figurative-language',\n",
       " 'category': 'Literary devices',\n",
       " 'skill': 'Interpret figures of speech',\n",
       " 'lecture': 'Figures of speech are words or phrases that use language in a nonliteral or unusual way. They can make writing more expressive.\\nVerbal irony involves saying one thing but implying something very different. People often use verbal irony when they are being sarcastic.\\nOlivia seems thrilled that her car keeps breaking down.\\nEach breakdown is as enjoyable as a punch to the face.',\n",
       " 'solution': \"The text uses verbal irony, which involves saying one thing but implying something very different.\\nAs quiet as a jackhammer suggests that the snoring is loud. A jackhammer is not quiet, and neither is Mr. Herrera's snoring.\",\n",
       " 'input': '',\n",
       " 'instruction': \"Context: N/A\\nQuestion: What does the verbal irony in this text suggest?\\nAccording to Mr. Herrera's kids, his snoring is as quiet as a jackhammer.\\nOptions: (A) The snoring is loud. (B) The snoring occurs in bursts.\\n\",\n",
       " 'output': 'Answer: The answer is A.'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_keys(json_data, key1, key2, new_key):\n",
    "    for item in json_data:\n",
    "        if key1 in item and key2 in item:\n",
    "            item[new_key] = f\"{item[key1]} {item[key2]}\"  # Customize how you combine values\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train=combine_keys(train,'instruction', 'output', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val=combine_keys(val,'instruction', 'output', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': None,\n",
       " 'question': 'Is this a sentence fragment?\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.',\n",
       " 'choices': ['no', 'yes'],\n",
       " 'answer': 'B',\n",
       " 'hint': '',\n",
       " 'task': 'yes or no',\n",
       " 'grade': 'grade12',\n",
       " 'subject': 'language science',\n",
       " 'topic': 'writing-strategies',\n",
       " 'category': 'Sentences, fragments, and run-ons',\n",
       " 'skill': 'Identify sentence fragments',\n",
       " 'lecture': \"A sentence is a group of words that expresses a complete thought.\\nThe band I'm in has been rehearsing daily because we have a concert in two weeks.\\nA sentence fragment is a group of words that does not express a complete thought.\\nRehearsing daily because we have a concert in two weeks.\\nThis fragment is missing a subject. It doesn't tell who is rehearsing.\\nThe band I'm in.\\nThis fragment is missing a verb. It doesn't tell what the band I'm in is doing.\\nBecause we have a concert in two weeks.\\nThis fragment is missing an independent clause. It doesn't tell what happened because of the concert.\",\n",
       " 'solution': 'This is a sentence fragment. It does not express a complete thought.\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.\\nHere is one way to fix the sentence fragment:\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock were removed from the mountain to create the monument.',\n",
       " 'input': '',\n",
       " 'instruction': 'Context: N/A\\nQuestion: Is this a sentence fragment?\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.\\nOptions: (A) no (B) yes\\n',\n",
       " 'output': 'Answer: The answer is B.',\n",
       " 'text': 'Context: N/A\\nQuestion: Is this a sentence fragment?\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.\\nOptions: (A) no (B) yes\\n Answer: The answer is B.'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': None,\n",
       " 'question': 'Is this a sentence fragment?\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.',\n",
       " 'choices': ['no', 'yes'],\n",
       " 'answer': 'B',\n",
       " 'hint': '',\n",
       " 'task': 'yes or no',\n",
       " 'grade': 'grade12',\n",
       " 'subject': 'language science',\n",
       " 'topic': 'writing-strategies',\n",
       " 'category': 'Sentences, fragments, and run-ons',\n",
       " 'skill': 'Identify sentence fragments',\n",
       " 'lecture': \"A sentence is a group of words that expresses a complete thought.\\nThe band I'm in has been rehearsing daily because we have a concert in two weeks.\\nA sentence fragment is a group of words that does not express a complete thought.\\nRehearsing daily because we have a concert in two weeks.\\nThis fragment is missing a subject. It doesn't tell who is rehearsing.\\nThe band I'm in.\\nThis fragment is missing a verb. It doesn't tell what the band I'm in is doing.\\nBecause we have a concert in two weeks.\\nThis fragment is missing an independent clause. It doesn't tell what happened because of the concert.\",\n",
       " 'solution': 'This is a sentence fragment. It does not express a complete thought.\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.\\nHere is one way to fix the sentence fragment:\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock were removed from the mountain to create the monument.',\n",
       " 'input': '',\n",
       " 'instruction': 'Context: N/A\\nQuestion: Is this a sentence fragment?\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.\\nOptions: (A) no (B) yes\\n',\n",
       " 'output': 'Answer: The answer is B.',\n",
       " 'text': 'Context: N/A\\nQuestion: Is this a sentence fragment?\\nDuring the construction of Mount Rushmore, approximately eight hundred million pounds of rock from the mountain to create the monument.\\nOptions: (A) no (B) yes\\n Answer: The answer is B.'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'input', 'instruction', 'output', 'text'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= Dataset.from_list(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'input', 'instruction', 'output', 'text'],\n",
       "    num_rows: 6508\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset.from_list(new_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'input', 'instruction', 'output', 'text'],\n",
       "    num_rows: 2144\n",
       "})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6508/6508 [00:00<00:00, 51566.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset.save_to_disk(\"qa_text_scienceq_train_IF.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2144/2144 [00:00<00:00, 41752.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset.save_to_disk(\"qa_text_scienceq_validation_IF.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = Dataset.from_list(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = Dataset.from_list(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.save_to_disk(\"qa_mrpc_test_IF.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_test=combine_keys(test,'instruction', 'output', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('qa_mrpc_train_IF.json', 'w') as f:\n",
    "#     json.dump(new_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('qa_mrpc_test_IF.json', 'w') as f:\n",
    "#     json.dump(new_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"qa_text_scienceq_train_IF.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_from_disk('/nas02/Hadi/Model-Selection-IF/alphalora/datasets/qa_text_scienceq_train_IF-short.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?',\n",
       " 'question_concept': 'punishing',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']},\n",
       " 'answerKey': 'A',\n",
       " 'answer': 'A',\n",
       " 'input': '',\n",
       " 'instruction': 'Question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\\nOptions: (A) ignore (B) enforce (C) authoritarian (D) yell at (E) avoid\\n',\n",
       " 'output': 'Answer: The answer is A.',\n",
       " 'text': 'Question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\\nOptions: (A) ignore (B) enforce (C) authoritarian (D) yell at (E) avoid\\n Answer: The answer is A.'}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"qa_text_scienceq_train_IF.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 300/300 [00:00<00:00, 15816.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "short_dataset = dataset.select(range(300))\n",
    "short_dataset.save_to_disk(\"qa_text_scienceq_train_IF-short.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"qa_text_scienceq_validation_IF.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 50/50 [00:00<00:00, 4753.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "short_dataset = dataset.select(range(50))\n",
    "short_dataset.save_to_disk(\"qa_text_scienceq_validation_IF-short.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphalora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
